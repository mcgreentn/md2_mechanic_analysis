{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dcb0e50",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "79cf642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import csv\n",
    "import json\n",
    "from scipy.stats import wasserstein_distance\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a78063",
   "metadata": {},
   "source": [
    "# Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "bbc31de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stats_data(name, mechanics, folder):\n",
    "    data = {}\n",
    "    for mech in mechanics:\n",
    "        data[mech] = []\n",
    "    data[\"endTurn\"] = []\n",
    "    file_names = [f for f in os.listdir(folder) if name in f]\n",
    "    for fn in file_names:\n",
    "        with open(os.path.join(folder,fn)) as f:\n",
    "            json_data = json.load(f)\n",
    "            if \"results\" in json_data:\n",
    "                json_data = json_data[\"results\"]\n",
    "            for playtrace in json_data:\n",
    "                for mech in mechanics:\n",
    "                    if mech in playtrace[\"frequencies\"]:\n",
    "                        data[mech].append(playtrace[\"frequencies\"][mech])\n",
    "                    else:\n",
    "                        data[mech].append(0.0)\n",
    "                data[\"endTurn\"].append(playtrace[\"levelReport\"][\"turnsTaken\"])\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def build_users_data(folder, mechanics, users):\n",
    "    full_data = read_stats_data(users[0], mechanics, folder)\n",
    "    full_data['id'] = users[0]\n",
    "    for user in users[1:]:\n",
    "        user_data = read_stats_data(user, mechanics, folder)\n",
    "        user_data['id'] = user\n",
    "        full_data = pd.concat([full_data, user_data])\n",
    "    full_data.set_index('id', inplace=True)\n",
    "    return full_data\n",
    "\n",
    "def read_questionaire(users, classes, scores, folder):\n",
    "    data = {}\n",
    "    for key in classes:\n",
    "        data[key] = []\n",
    "    data['id'] = []\n",
    "    for user in users:\n",
    "        data['id'].append(user)\n",
    "        with open(os.path.join(folder, user + \".json\")) as f:\n",
    "            json_data = json.load(f)\n",
    "            if \"Q1\" in json_data:\n",
    "                for key in classes:\n",
    "                    data[key].append(0.0)\n",
    "                    for q in classes[key]:\n",
    "                        data[key][-1] += scores[json_data[q]]\n",
    "                    data[key][-1] /= len(classes[key])\n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index('id', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41337314",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e98ad5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mechanics(folders):\n",
    "    uniques = set()\n",
    "    for folder in folders:\n",
    "        filenames = [f for f in os.listdir(folder) if \".json\" in f]\n",
    "        for fn in filenames:\n",
    "            with open(os.path.join(folder,fn)) as f:\n",
    "                json_data = json.load(f)\n",
    "                if \"results\" in json_data:\n",
    "                    json_data = json_data[\"results\"]\n",
    "                for playtrace in json_data:\n",
    "                    for key in playtrace[\"frequencies\"].keys():\n",
    "                        uniques.add(key)\n",
    "    return list(uniques)\n",
    "\n",
    "def get_users(folders):\n",
    "    uniques = set()\n",
    "    for folder in folders:\n",
    "        filenames = [f for f in os.listdir(folder) if \".json\" in f]\n",
    "        for fn in filenames:\n",
    "            uuid = fn.split(\".\")[0]\n",
    "            uniques.add(uuid)\n",
    "    return list(uniques)\n",
    "\n",
    "def get_majority_voting(clf, data):\n",
    "    labels = clf.predict(data).reshape((-1,3))\n",
    "    result = []\n",
    "    for row in labels:\n",
    "        vals,counts= np.unique(row, return_counts=True)\n",
    "        index = np.argmax(counts)\n",
    "        result.append(vals[index])\n",
    "    return np.array(result)\n",
    "\n",
    "def divide_data_set(input_data, output_data, percentage):\n",
    "    indeces = list(range(len(input_data)))\n",
    "    random.shuffle(indeces)\n",
    "    size = int(percentage * len(indeces))\n",
    "    train_set, train_label, val_data, val_label = [],[],[],[]\n",
    "    for i in range(size):\n",
    "        train_set.append(input_data[indeces[i]])\n",
    "        train_label.append(output_data[indeces[i]])\n",
    "    for i in range(size,len(indeces)):\n",
    "        val_data.append(input_data[indeces[i]]) \n",
    "        val_label.append(output_data[indeces[i]])\n",
    "    return np.array(train_set), np.array(train_label), np.array(val_data), np.array(val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e401e",
   "metadata": {},
   "source": [
    "# Building Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "244997e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanics = get_mechanics([\"results\", \"results_study\"])\n",
    "users = get_users([\"results_study\"])\n",
    "classes = {\n",
    "    \"MK\": [\"Q5\", \"Q6\", \"Q10\"],\n",
    "    \"TC\": [\"Q3\", \"Q4\", \"Q8\"],\n",
    "    \"R\": [\"Q2\", \"Q7\", \"Q9\"]\n",
    "}\n",
    "scores = {\n",
    "    \"Never\": 0, \n",
    "    \"Rarely\": 1, \n",
    "    \"Sometimes\": 2, \n",
    "    \"Often\": 3, \n",
    "    \"Always\": 4\n",
    "}\n",
    "labels = {\n",
    "    \"MK\": 0,\n",
    "    \"TC\": 1,\n",
    "    \"R\": 2\n",
    "}\n",
    "\n",
    "# Reading all the data file\n",
    "mk_data = read_stats_data(\"MK\", mechanics, \"results\")\n",
    "tc_data = read_stats_data(\"TC\", mechanics, \"results\")\n",
    "r_data = read_stats_data(\"R\", mechanics, \"results\")\n",
    "user_data = build_users_data(\"results_study\", mechanics, users)\n",
    "ques_data = read_questionaire(users, classes, scores, \"results_study\")\n",
    "\n",
    "# Removing User Data that didn't do any of the questionaire\n",
    "user_filter = ques_data['MK'] + ques_data['TC'] + ques_data['R'] > 0\n",
    "user_indeces = ques_data.index[user_filter]\n",
    "\n",
    "user_data = user_data.loc[user_indeces]\n",
    "ques_data = ques_data.loc[user_indeces]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d76173e",
   "metadata": {},
   "source": [
    "# Building Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "59b137fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.concat([mk_data, tc_data, r_data], ignore_index=True).to_numpy()\n",
    "output_data = pd.Series([0]*len(mk_data) + [1]*len(tc_data) + [2]*len(r_data)).to_numpy()\n",
    "avg_test_set = user_data.groupby('id').mean().to_numpy()\n",
    "maj_test_set = user_data.to_numpy()\n",
    "ques_set = ques_data.to_numpy()\n",
    "\n",
    "total_data = np.concatenate((input_data, avg_test_set, maj_test_set)) \n",
    "\n",
    "n_input_data = input_data / total_data.max(axis=0)\n",
    "n_avg_test_set = avg_test_set / total_data.max(axis=0)\n",
    "n_maj_test_set = maj_test_set / total_data.max(axis=0)\n",
    "n_ques_set = ques_set / ques_set.sum(axis=1).reshape(-1,1).repeat(3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2c915",
   "metadata": {},
   "source": [
    "# Training Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "bf16591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training Score: 0.8328571428571429\n",
      "Decision Tree Validation Score: 0.8144444444444444\n",
      "\n",
      "K Nearest Neighbor Training Score: 0.909047619047619\n",
      "K Nearest Neighbor Validation Score: 0.84\n",
      "\n",
      "Support Vector Machine Training Score: 0.8471428571428572\n",
      "Support Vector Machine Validation Score: 0.8377777777777777\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label,val_data,val_label = divide_data_set(n_input_data, output_data, 0.7)\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_depth=5)\n",
    "dt = dt.fit(train_data, train_label)\n",
    "print(f\"Decision Tree Training Score: {dt.score(train_data, train_label)}\")\n",
    "print(f\"Decision Tree Validation Score: {dt.score(val_data, val_label)}\\n\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = knn.fit(train_data, train_label)\n",
    "print(f\"K Nearest Neighbor Training Score: {knn.score(train_data, train_label)}\")\n",
    "print(f\"K Nearest Neighbor Validation Score: {knn.score(val_data, val_label)}\\n\")\n",
    "\n",
    "svc = svm.SVC(decision_function_shape='ovo', probability=True)\n",
    "svc = svc.fit(train_data, train_label)\n",
    "print(f\"Support Vector Machine Training Score: {svc.score(train_data, train_label)}\")\n",
    "print(f\"Support Vector Machine Validation Score: {svc.score(val_data, val_label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad94001",
   "metadata": {},
   "source": [
    "# Predicting Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "5784d094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average DT vs KNN: 0.6095238095238096\n",
      "Average DT vs SVC: 0.6761904761904762\n",
      "Average KNN vs SVC: 0.7523809523809524\n",
      "Majority DT vs KNN: 0.6142857142857143\n",
      "Majority DT vs SVC: 0.6190476190476191\n",
      "Majority KNN vs SVC: 0.861904761904762\n"
     ]
    }
   ],
   "source": [
    "dt_avg_probs = dt.predict_proba(n_avg_test_set)\n",
    "knn_avg_probs = knn.predict_proba(n_avg_test_set)\n",
    "svc_avg_probs = svc.predict_proba(n_avg_test_set)\n",
    "\n",
    "dt_avg_labels = dt.predict(n_avg_test_set)\n",
    "knn_avg_labels = knn.predict(n_avg_test_set)\n",
    "svc_avg_labels = svc.predict(n_avg_test_set)\n",
    "\n",
    "print(f\"Average DT vs KNN: {(dt_avg_labels == knn_avg_labels).sum()/len(avg_test_set)}\")\n",
    "print(f\"Average DT vs SVC: {(dt_avg_labels == svc_avg_labels).sum()/len(avg_test_set)}\")\n",
    "print(f\"Average KNN vs SVC: {(knn_avg_labels == svc_avg_labels).sum()/len(avg_test_set)}\")\n",
    "\n",
    "dt_maj_labels = get_majority_voting(dt, n_maj_test_set)\n",
    "knn_maj_labels = get_majority_voting(knn, n_maj_test_set)\n",
    "svc_maj_labels = get_majority_voting(svc, n_maj_test_set)\n",
    "\n",
    "dt_maj_probs = dt.predict_proba(n_maj_test_set).reshape((-1,3,3)).mean(axis=1)\n",
    "knn_maj_probs = knn.predict_proba(n_maj_test_set).reshape((-1,3,3)).mean(axis=1)\n",
    "svc_maj_probs = svc.predict_proba(n_maj_test_set).reshape((-1,3,3)).mean(axis=1)\n",
    "\n",
    "print(f\"Majority DT vs KNN: {(dt_maj_labels == knn_maj_labels).sum()/len(avg_test_set)}\")\n",
    "print(f\"Majority DT vs SVC: {(dt_maj_labels == svc_maj_labels).sum()/len(avg_test_set)}\")\n",
    "print(f\"Majority KNN vs SVC: {(knn_maj_labels == svc_maj_labels).sum()/len(avg_test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f7576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python391jvsc74a57bd024e6b29142bd44354db0d592add29d68e9ab4027b35f4ad05b8eab4548619476"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
