{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0dcfad",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "from plotly.subplots import make_subplots\n",
    "import csv\n",
    "import json\n",
    "from scipy.stats import wasserstein_distance\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa917c4",
   "metadata": {},
   "source": [
    "# Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stats_data(name, mechanics, folder):\n",
    "    data = {}\n",
    "    for mech in mechanics:\n",
    "        data[mech] = []\n",
    "    data[\"EndTurn\"] = []\n",
    "    data[\"MapNumber\"] = []\n",
    "    file_names = [f for f in os.listdir(folder) if name in f]\n",
    "    for fn in file_names:\n",
    "        with open(os.path.join(folder,fn)) as f:\n",
    "            json_data = json.load(f)\n",
    "            if \"results\" in json_data:\n",
    "                json_data = json_data[\"results\"]\n",
    "            for playtrace in json_data:\n",
    "                for mech in mechanics:\n",
    "                    if mech in playtrace[\"frequencies\"]:\n",
    "                        data[mech].append(playtrace[\"frequencies\"][mech])\n",
    "                    else:\n",
    "                        data[mech].append(0.0)\n",
    "                data[\"EndTurn\"].append(playtrace[\"levelReport\"][\"turnsTaken\"])\n",
    "                if \"map_number\" in playtrace:\n",
    "                    data[\"MapNumber\"].append(int(playtrace[\"map_number\"]))\n",
    "                else:\n",
    "                    data[\"MapNumber\"].append(int(re.findall(\"\\d+\", fn)[0]))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def build_users_data(folder, mechanics, users):\n",
    "    full_data = read_stats_data(users[0], mechanics, folder)\n",
    "    full_data['id'] = users[0]\n",
    "    for user in users[1:]:\n",
    "        user_data = read_stats_data(user, mechanics, folder)\n",
    "        user_data['id'] = user\n",
    "        full_data = pd.concat([full_data, user_data])\n",
    "    full_data.set_index('id', inplace=True)\n",
    "    return full_data\n",
    "\n",
    "def read_questionaire(users, classes, scores, folder):\n",
    "    data = {}\n",
    "    for key in classes:\n",
    "        data[key] = []\n",
    "    data['id'] = []\n",
    "    for user in users:\n",
    "        data['id'].append(user)\n",
    "        with open(os.path.join(folder, user + \".json\")) as f:\n",
    "            json_data = json.load(f)\n",
    "            if \"Q1\" in json_data:\n",
    "                for key in classes:\n",
    "                    data[key].append(0.0)\n",
    "                    for q in classes[key]:\n",
    "                        data[key][-1] += scores[json_data[q]]\n",
    "                    data[key][-1] /= len(classes[key])\n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index('id', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f252cb",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854779e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mechanics(folders):\n",
    "    uniques = set()\n",
    "    for folder in folders:\n",
    "        filenames = [f for f in os.listdir(folder) if \".json\" in f]\n",
    "        for fn in filenames:\n",
    "            with open(os.path.join(folder,fn)) as f:\n",
    "                json_data = json.load(f)\n",
    "                if \"results\" in json_data:\n",
    "                    json_data = json_data[\"results\"]\n",
    "                for playtrace in json_data:\n",
    "                    for key in playtrace[\"frequencies\"].keys():\n",
    "                        uniques.add(key)\n",
    "    return list(uniques)\n",
    "\n",
    "def get_users(folders):\n",
    "    uniques = set()\n",
    "    for folder in folders:\n",
    "        filenames = [f for f in os.listdir(folder) if \".json\" in f]\n",
    "        for fn in filenames:\n",
    "            uuid = fn.split(\".\")[0]\n",
    "            uniques.add(uuid)\n",
    "    return list(uniques)\n",
    "\n",
    "def get_majority_voting(clf, data):\n",
    "    labels = clf.predict(data).reshape((-1,3))\n",
    "    result = []\n",
    "    for row in labels:\n",
    "        vals,counts= np.unique(row, return_counts=True)\n",
    "        index = np.argmax(counts)\n",
    "        result.append(vals[index])\n",
    "    return np.array(result)\n",
    "\n",
    "def divide_data_set(input_data, output_data, percentage):\n",
    "    indeces = list(range(len(input_data)))\n",
    "    random.shuffle(indeces)\n",
    "    size = int(percentage * len(indeces))\n",
    "    train_set, train_label, val_data, val_label = [],[],[],[]\n",
    "    for i in range(size):\n",
    "        train_set.append(input_data[indeces[i]])\n",
    "        train_label.append(output_data[indeces[i]])\n",
    "    for i in range(size,len(indeces)):\n",
    "        val_data.append(input_data[indeces[i]]) \n",
    "        val_label.append(output_data[indeces[i]])\n",
    "    return np.array(train_set), np.array(train_label), np.array(val_data), np.array(val_label)\n",
    "\n",
    "def filter_traces(data, column, value, IsUser=None):\n",
    "    remove_columns = (data.columns != 'IsUser') & (data.columns != 'Label')\n",
    "    if column != 'index':\n",
    "        filter_values = data[column] == value\n",
    "        if IsUser != None:\n",
    "            filter_values = filter_values & (data[\"IsUser\"] == IsUser)\n",
    "        return data.loc[filter_values, remove_columns]\n",
    "    else:\n",
    "        new_data = data[data.index == value]\n",
    "        filter_values = [True] * len(new_data)\n",
    "        if IsUser != None:\n",
    "            filter_values = filter_values & (new_data[\"IsUser\"] == IsUser)\n",
    "        return new_data.loc[filter_values, remove_columns]\n",
    "\n",
    "def calc_mech_importance(fil_data, all_data, mech):\n",
    "    fil_array = fil_data[mech].to_numpy()\n",
    "    all_array = all_data[mech].to_numpy()\n",
    "    sign = np.sign(fil_array.mean() - all_array.mean())\n",
    "    if sign == 0:\n",
    "        sign = 1\n",
    "    value = wasserstein_distance(fil_array, all_array)\n",
    "    return sign * value\n",
    "\n",
    "def calc_mech_axis(data, column, values, mechanics):\n",
    "    value_temp = {}\n",
    "    row_index = []\n",
    "    for mech in mechanics:\n",
    "        value_temp[mech] = []\n",
    "        for v in values:\n",
    "            traces = filter_traces(data, column, v)\n",
    "            if len(traces) > 0:\n",
    "                value_temp[mech].append(calc_mech_importance(traces, data, mech))\n",
    "                if v not in row_index:\n",
    "                    row_index.append(v)\n",
    "    return pd.DataFrame(value_temp, index=row_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab69b05",
   "metadata": {},
   "source": [
    "# Render Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mech_graph(data, title):\n",
    "    colors = ['#FD3216', '#00FE35', '#6A76FC', '#FED4C4', '#FE00CE', \n",
    "          '#0DF9FF', '#F6F926', '#FF9616', '#479B55', '#EEA6FB', \n",
    "          '#DC587D', '#D626FF', '#6E899C', '#00B5F7', '#B68E00', \n",
    "          '#C9FBE5', '#FF0092', '#22FFA7', '#E3EE9E', '#86CE00', \n",
    "          '#BC7196', '#7E7DCD', '#FC6955', '#E48F72']\n",
    "    \n",
    "    fig = go.Figure(layout={\"width\": 500, \"height\":500})\n",
    "    # Draw Sectors\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=0, y0=0, x1=1.2, y1=1.2,\n",
    "        line=dict(color=\"#43a047\"),\n",
    "        fillcolor=\"#76d275\",\n",
    "        layer=\"below\",\n",
    "        opacity=0.5\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=0, y0=0, x1=-1.2, y1=-1.2,\n",
    "        line=dict(color=\"#e53935\"),\n",
    "        fillcolor=\"#ff6f60\",\n",
    "        layer=\"below\",\n",
    "        opacity=0.5\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=0, y0=0, x1=1.2, y1=-1.2,\n",
    "        line=dict(color=\"#2196f3\"),\n",
    "        fillcolor=\"#6ec6ff\",\n",
    "        layer=\"below\",\n",
    "        opacity=0.5\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=0, y0=0, x1=-1.2, y1=1.2,\n",
    "        line=dict(color=\"#fbc02d\"),\n",
    "        fillcolor=\"#fff263\",\n",
    "        layer=\"below\",\n",
    "        opacity=0.5\n",
    "    )\n",
    "\n",
    "\n",
    "    for idx, entry in enumerate(data):\n",
    "        x_values = entry[2]\n",
    "        y_values = entry[3]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_values,\n",
    "                y=y_values,\n",
    "                mode='markers',\n",
    "                marker_symbol=idx,\n",
    "                marker=dict(\n",
    "                    color=colors,\n",
    "                    size=15,\n",
    "                    line=dict(width=1,color='DarkSlateGrey')),\n",
    "                text=entry[1],\n",
    "                name=entry[0]\n",
    "            )\n",
    "        )\n",
    "    fig.update_layout(title_text=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203274fd",
   "metadata": {},
   "source": [
    "# Building Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanics = get_mechanics([\"results\", \"results_study\"])\n",
    "users = get_users([\"results_study\"])\n",
    "classes = {\n",
    "    \"MK\": [\"Q5\", \"Q6\", \"Q10\"],\n",
    "    \"TC\": [\"Q3\", \"Q4\", \"Q8\"],\n",
    "    \"R\": [\"Q2\", \"Q7\", \"Q9\"]\n",
    "}\n",
    "scores = {\n",
    "    \"Never\": 0, \n",
    "    \"Rarely\": 1, \n",
    "    \"Sometimes\": 2, \n",
    "    \"Often\": 3, \n",
    "    \"Always\": 4\n",
    "}\n",
    "labels = {\n",
    "    \"MK\": 0,\n",
    "    \"TC\": 1,\n",
    "    \"R\": 2\n",
    "}\n",
    "kill_mechanics = [\"OgreHit\", \"GoblinMeleeHit\", \"GoblinRangedHit\", \"BlobHit\"]\n",
    "\n",
    "# Reading all the data file\n",
    "mk_data = read_stats_data(\"MK\", mechanics, \"results\")\n",
    "mk_data[\"EnemyKill\"] = 0\n",
    "for kill in kill_mechanics:\n",
    "    mk_data[\"EnemyKill\"] += mk_data[kill]\n",
    "tc_data = read_stats_data(\"TC\", mechanics, \"results\")\n",
    "tc_data[\"EnemyKill\"] = 0\n",
    "for kill in kill_mechanics:\n",
    "    tc_data[\"EnemyKill\"] += tc_data[kill]\n",
    "r_data = read_stats_data(\"R\", mechanics, \"results\")\n",
    "r_data[\"EnemyKill\"] = 0\n",
    "for kill in kill_mechanics:\n",
    "    r_data[\"EnemyKill\"] += r_data[kill]\n",
    "user_data = build_users_data(\"results_study\", mechanics, users)\n",
    "user_data[\"EnemyKill\"] = 0\n",
    "for kill in kill_mechanics:\n",
    "    user_data[\"EnemyKill\"] += user_data[kill]\n",
    "ques_data = read_questionaire(users, classes, scores, \"results_study\")\n",
    "\n",
    "# Removing User Data that didn't do any of the questionaire\n",
    "user_filter = ques_data['MK'] + ques_data['TC'] + ques_data['R'] > 0\n",
    "user_indeces = ques_data.index[user_filter]\n",
    "\n",
    "user_data = user_data.loc[user_indeces]\n",
    "ques_data = ques_data.loc[user_indeces]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b8f38",
   "metadata": {},
   "source": [
    "# Combine All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = mk_data.copy()\n",
    "temp_data[\"Label\"] = \"MK\"\n",
    "temp_data[\"IsUser\"] = False\n",
    "total_data = pd.concat([temp_data], ignore_index=True)\n",
    "temp_data = tc_data.copy()\n",
    "temp_data[\"Label\"] = \"TC\"\n",
    "temp_data[\"IsUser\"] = False\n",
    "total_data = pd.concat([total_data, temp_data], ignore_index=True)\n",
    "temp_data = r_data.copy()\n",
    "temp_data[\"Label\"] = \"R\"\n",
    "temp_data[\"IsUser\"] = False\n",
    "total_data = pd.concat([total_data, temp_data], ignore_index=True)\n",
    "temp_data = user_data.copy()\n",
    "temp_data[\"Label\"] = \"\"\n",
    "temp_data[\"IsUser\"] = True\n",
    "total_data = pd.concat([total_data, temp_data])\n",
    "    \n",
    "n_total_data = total_data.copy()\n",
    "for col in n_total_data.columns:\n",
    "    if col == \"Label\" or col == \"IsUser\" or col == \"MapNumber\":\n",
    "        continue\n",
    "    n_total_data[col] /= 1.0 * n_total_data[col].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dc4370",
   "metadata": {},
   "source": [
    "# Building Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_mechs = [\"MapNumber\"]\n",
    "\n",
    "input_data = pd.concat([mk_data.drop(columns=remove_mechs), tc_data.drop(columns=remove_mechs), r_data.drop(columns=remove_mechs)], ignore_index=True).to_numpy()\n",
    "output_data = pd.Series([0]*len(mk_data) + [1]*len(tc_data) + [2]*len(r_data)).to_numpy()\n",
    "avg_test_set = user_data.drop(columns=remove_mechs).groupby('id').mean().to_numpy()\n",
    "maj_test_set = user_data.drop(columns=remove_mechs).to_numpy()\n",
    "ques_set = ques_data.to_numpy()\n",
    "\n",
    "total_set = np.concatenate((input_data, avg_test_set, maj_test_set)) \n",
    "\n",
    "n_input_data = input_data / total_set.max(axis=0)\n",
    "n_avg_test_set = avg_test_set / total_set.max(axis=0)\n",
    "n_maj_test_set = maj_test_set / total_set.max(axis=0)\n",
    "n_ques_set = ques_set / ques_set.sum(axis=1).reshape(-1,1).repeat(3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc092c",
   "metadata": {},
   "source": [
    "# Training Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc451a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,train_label,val_data,val_label = divide_data_set(n_input_data, output_data, 0.7)\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_depth=5)\n",
    "dt = dt.fit(train_data, train_label)\n",
    "print(f\"Decision Tree Training Score: {dt.score(train_data, train_label)}\")\n",
    "print(f\"Decision Tree Validation Score: {dt.score(val_data, val_label)}\\n\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = knn.fit(train_data, train_label)\n",
    "print(f\"K Nearest Neighbor Training Score: {knn.score(train_data, train_label)}\")\n",
    "print(f\"K Nearest Neighbor Validation Score: {knn.score(val_data, val_label)}\\n\")\n",
    "\n",
    "svc = svm.SVC(decision_function_shape='ovo', probability=True)\n",
    "svc = svc.fit(train_data, train_label)\n",
    "print(f\"Support Vector Machine Training Score: {svc.score(train_data, train_label)}\")\n",
    "print(f\"Support Vector Machine Validation Score: {svc.score(val_data, val_label)}\")\n",
    "\n",
    "dt = dt.fit(n_input_data, output_data)\n",
    "knn = knn.fit(n_input_data, output_data)\n",
    "svc = svc.fit(n_input_data, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d11d49",
   "metadata": {},
   "source": [
    "# Predicting Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbff652",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_avg_probs = dt.predict_proba(n_avg_test_set)\n",
    "knn_avg_probs = knn.predict_proba(n_avg_test_set)\n",
    "svc_avg_probs = svc.predict_proba(n_avg_test_set)\n",
    "\n",
    "dt_avg_labels = dt.predict(n_avg_test_set)\n",
    "knn_avg_labels = knn.predict(n_avg_test_set)\n",
    "svc_avg_labels = svc.predict(n_avg_test_set)\n",
    "\n",
    "print(f\"Average DT vs KNN: {(dt_avg_labels == knn_avg_labels).sum()/len(avg_test_set)}\")\n",
    "print(f\"Average DT vs SVC: {(dt_avg_labels == svc_avg_labels).sum()/len(avg_test_set)}\")\n",
    "print(f\"Average KNN vs SVC: {(knn_avg_labels == svc_avg_labels).sum()/len(avg_test_set)}\")\n",
    "\n",
    "dt_maj_labels = get_majority_voting(dt, n_maj_test_set)\n",
    "knn_maj_labels = get_majority_voting(knn, n_maj_test_set)\n",
    "svc_maj_labels = get_majority_voting(svc, n_maj_test_set)\n",
    "\n",
    "dt_maj_probs = dt.predict_proba(n_maj_test_set).reshape((-1,3,3)).mean(axis=1)\n",
    "knn_maj_probs = knn.predict_proba(n_maj_test_set).reshape((-1,3,3)).mean(axis=1)\n",
    "svc_maj_probs = svc.predict_proba(n_maj_test_set).reshape((-1,3,3)).mean(axis=1)\n",
    "\n",
    "print(f\"Majority DT vs KNN: {(dt_maj_labels == knn_maj_labels).sum()/len(avg_test_set)}\")\n",
    "print(f\"Majority DT vs SVC: {(dt_maj_labels == svc_maj_labels).sum()/len(avg_test_set)}\")\n",
    "print(f\"Majority KNN vs SVC: {(knn_maj_labels == svc_maj_labels).sum()/len(avg_test_set)}\")\n",
    "\n",
    "print(f\"Probability Distribution of DT: {dt_maj_probs.mean(axis=0)}\")\n",
    "print(f\"Probability Distribution of KNN: {knn_maj_probs.mean(axis=0)}\")\n",
    "print(f\"Probability Distribution of SVC: {svc_maj_probs.mean(axis=0)}\")\n",
    "print(f\"Probability Distribution of User Questionaire: {n_ques_set.mean(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919ec19",
   "metadata": {},
   "source": [
    "# Calculating Mechanic Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_mechs = mechanics + [\"EndTurn\", \"EnemyKill\"]\n",
    "\n",
    "x_import = calc_mech_axis(n_total_data, \"ReachStairs\", [0, 1], import_mechs)\n",
    "y_import = calc_mech_axis(n_total_data, \"Label\", labels.keys(), import_mechs)\n",
    "user_import = calc_mech_axis(n_total_data, \"index\", users, import_mechs)\n",
    "\n",
    "dt_data = n_total_data.copy()\n",
    "dt_data[\"Label\"] = \"\"\n",
    "for i, label in enumerate(dt_maj_labels):\n",
    "    index = dt_data[dt_data[\"IsUser\"] == True].index[i*3]\n",
    "    dt_data.loc[index, \"Label\"] = list(labels.keys())[label]\n",
    "    \n",
    "dt_import = calc_mech_axis(dt_data, \"Label\", labels.keys(), import_mechs)\n",
    "    \n",
    "knn_data = n_total_data.copy()\n",
    "knn_data[\"Label\"] = \"\"\n",
    "for i, label in enumerate(knn_maj_labels):\n",
    "    index = knn_data[knn_data[\"IsUser\"] == True].index[i*3]\n",
    "    knn_data.loc[index, \"Label\"] = list(labels.keys())[label]\n",
    "    \n",
    "knn_import = calc_mech_axis(knn_data, \"Label\", labels.keys(), import_mechs)\n",
    "    \n",
    "svc_data = n_total_data.copy()\n",
    "svc_data[\"Label\"] = \"\"\n",
    "for i, label in enumerate(svc_maj_labels):\n",
    "    index = svc_data[svc_data[\"IsUser\"] == True].index[i*3]\n",
    "    svc_data.loc[index, \"Label\"] = list(labels.keys())[label]\n",
    "    \n",
    "svc_import = calc_mech_axis(svc_data, \"Label\", labels.keys(), import_mechs)\n",
    "\n",
    "uq_data = n_total_data.copy()\n",
    "uq_data[\"Label\"] = \"\"\n",
    "for u in users:\n",
    "    if u in ques_data.index:\n",
    "        q_value = ques_data.loc[u]\n",
    "        uq_data.loc[u, \"Label\"] = q_value.index[q_value.argmax()]\n",
    "\n",
    "uq_import = calc_mech_axis(uq_data, \"Label\", labels.keys(), import_mechs)\n",
    "\n",
    "\n",
    "temp_data = [mk_data.copy(), tc_data.copy(), r_data.copy()]\n",
    "temp_data[0][\"Label\"] = \"MK\"\n",
    "temp_data[0][\"IsUser\"] = False\n",
    "temp_data[1][\"Label\"] = \"TC\"\n",
    "temp_data[1][\"IsUser\"] = False\n",
    "temp_data[2][\"Label\"] = \"R\"\n",
    "temp_data[2][\"IsUser\"] = False\n",
    "a_no_user_data = pd.concat(temp_data, ignore_index=True)\n",
    "# Normalize the data frame\n",
    "for col in a_no_user_data.columns:\n",
    "    if col == \"Label\" or col == \"IsUser\" or col == \"MapNumber\":\n",
    "        continue\n",
    "    a_no_user_data[col] /= 1.0 * total_data[col].max()\n",
    "a_no_user_import = calc_mech_axis(a_no_user_data, \"Label\", labels.keys(), import_mechs)\n",
    "\n",
    "uq_no_agent_data = user_data.copy()\n",
    "uq_no_agent_data[\"Label\"] = \"\"\n",
    "for u in users:\n",
    "    if u in ques_data.index:\n",
    "        q_value = ques_data.loc[u]\n",
    "        uq_no_agent_data.loc[u, \"Label\"] = q_value.index[q_value.argmax()]\n",
    "# Normalize the data frame\n",
    "for col in uq_no_agent_data.columns:\n",
    "    if col == \"Label\" or col == \"IsUser\" or col == \"MapNumber\":\n",
    "        continue\n",
    "    uq_no_agent_data[col] /= 1.0 * total_data[col].max()\n",
    "uq_no_agent_import = calc_mech_axis(uq_no_agent_data, \"Label\", labels.keys(), import_mechs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = total_data[total_data[\"IsUser\"]==False]\n",
    "agent_data = total_data[total_data[\"IsUser\"]==True]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_no_user_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04888f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "uq_no_agent_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x_import = x_import / max(x_import.loc[1].max(), abs(x_import.loc[1].min()))\n",
    "total_y_import = pd.concat([y_import, dt_import, knn_import, svc_import, uq_import])\n",
    "n_y_import = y_import / max(total_y_import.max().max(), abs(total_y_import.min().min()))\n",
    "n_dt_import = dt_import / max(total_y_import.max().max(), abs(total_y_import.min().min()))\n",
    "n_svc_import = svc_import / max(total_y_import.max().max(), abs(total_y_import.min().min()))\n",
    "n_knn_import = knn_import / max(total_y_import.max().max(), abs(total_y_import.min().min()))\n",
    "n_uq_import = uq_import / max(total_y_import.max().max(), abs(total_y_import.min().min()))\n",
    "\n",
    "total_ynew_import = pd.concat([uq_no_agent_import.copy(), a_no_user_import.copy()], ignore_index=True)\n",
    "n_uq_no_agent_import = uq_no_agent_import / max(total_ynew_import.max().max(), abs(total_ynew_import.min().min()))\n",
    "n_a_no_user_import = a_no_user_import / max(total_ynew_import.max().max(), abs(total_ynew_import.min().min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31abcb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_uq_no_agent_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e429bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a_no_user_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7deef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ynew_import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d49df2",
   "metadata": {},
   "source": [
    "# Draw Mech Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_import = {\n",
    "    # \"AGENT\": n_y_import,\n",
    "    # \"SVM\": n_svc_import,\n",
    "    # \"KNN\": n_knn_import,\n",
    "    # \"DT\": n_dt_import,\n",
    "    # \"USER\": n_uq_import,\n",
    "    \"U_USER\": n_uq_no_agent_import,\n",
    "    \"A_AGENT\": n_a_no_user_import\n",
    "}\n",
    "\n",
    "remove_mechs = [\"OgreHit\", \"GoblinMeleeHit\", \"GoblinRangedHit\", \"BlobHit\", \n",
    "                \"JavelinThrow\", \"OgreTreasure\", \"BlobCombine\", \"BlobPotion\"]\n",
    "\n",
    "# for algo in algo_import.keys():\n",
    "#     data = []\n",
    "#     for persona in labels.keys():\n",
    "#         x_values = []\n",
    "#         y_values = []\n",
    "#         mech_values = []\n",
    "#         for mech in import_mechs:\n",
    "#             if mech in remove_mechs:\n",
    "#                 continue\n",
    "#             x_values.append(n_x_import[mech][1])\n",
    "#             y_values.append(algo_import[algo][mech][persona])\n",
    "#             mech_values.append(mech)\n",
    "#         data.append((persona, mech_values, np.array(x_values), np.array(y_values)))\n",
    "#     draw_mech_graph(data, algo)\n",
    "\n",
    "all_data = {}\n",
    "for persona in labels.keys():\n",
    "    data = []\n",
    "    for algo in algo_import.keys():\n",
    "        x_values = []\n",
    "        y_values = []\n",
    "        mech_values = []\n",
    "        for mech in import_mechs:\n",
    "            if mech in remove_mechs:\n",
    "                continue\n",
    "            x_values.append(n_x_import[mech][1])\n",
    "            y_values.append(algo_import[algo][mech][persona])\n",
    "            mech_values.append(mech)\n",
    "        data.append((algo, mech_values, np.array(x_values), np.array(y_values)))\n",
    "        all_data[persona] = data\n",
    "    draw_mech_graph(data, persona)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3356e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for per in [\"MK\", \"TC\", \"R\"]:\n",
    "    print(f\"*** {per} ***\")\n",
    "    print(all_data[per][0][0])\n",
    "    print(all_data[per][0][3])\n",
    "    print(all_data[per][1][0])\n",
    "    print(all_data[per][1][3])\n",
    "    cs = cosine_similarity(all_data[per][0][3].reshape(1, -1), all_data[per][1][3].reshape(1, -1))\n",
    "    print(f\"CS: {cs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ba0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for per1 in [\"MK\", \"TC\", \"R\"]: \n",
    "    for per2 in [\"MK\", \"TC\", \"R\"]:\n",
    "        value = cosine_similarity(n_a_no_user_import.loc[per1].to_numpy().reshape(1,-1), \n",
    "                                  n_uq_no_agent_import.loc[per2].to_numpy().reshape(1,-1))\n",
    "        print(f\"Agent - {per1} | User - {per2}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff955dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a_no_user_import.loc[\"MK\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f332e2",
   "metadata": {},
   "source": [
    "# Checking Similarity between Mechanic Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in algo_import.keys():\n",
    "    if algo == \"AGENT\":\n",
    "        continue\n",
    "    data = []\n",
    "    label_x = list(labels.keys())[::-1]\n",
    "    label_y = list(labels.keys())\n",
    "    agent_import = algo_import[\"AGENT\"]\n",
    "    clf_import = algo_import[algo]\n",
    "    for p_x in label_x:\n",
    "        data.append([])\n",
    "        for p_y in label_y:\n",
    "            agent_persona = agent_import.loc[p_x].to_numpy().reshape((1,-1))\n",
    "            clf_persona = clf_import.loc[p_y].to_numpy().reshape((1, -1))\n",
    "            data[-1].append(cosine_similarity(agent_persona, clf_persona)[0][0])\n",
    "    plt.figure()\n",
    "    plt.imshow(np.array(data).reshape((3,3,1)), cmap='RdBu',  vmin=-0.9, vmax=0.9)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(label_y)),label_y)\n",
    "    plt.yticks(range(len(label_x)),label_x)\n",
    "    plt.ylabel(\"Agent\")\n",
    "    plt.xlabel(algo)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Agent_{algo}.pdf\", bbox_inches='tight')\n",
    "    \n",
    "for algo in algo_import.keys():\n",
    "    if algo == \"USER\":\n",
    "        continue\n",
    "    data = []\n",
    "    label_x = list(labels.keys())[::-1]\n",
    "    label_y = list(labels.keys())\n",
    "    agent_import = algo_import[\"USER\"]\n",
    "    clf_import = algo_import[algo]\n",
    "    for p_x in label_x:\n",
    "        data.append([])\n",
    "        for p_y in label_y:\n",
    "            agent_persona = agent_import.loc[p_x].to_numpy().reshape((1,-1))\n",
    "            clf_persona = clf_import.loc[p_y].to_numpy().reshape((1, -1))\n",
    "            data[-1].append(cosine_similarity(agent_persona, clf_persona)[0][0])\n",
    "    plt.figure()\n",
    "    plt.imshow(np.array(data).reshape((3,3,1)), cmap='RdBu',  vmin=-0.9, vmax=0.9)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(label_y)),label_y)\n",
    "    plt.yticks(range(len(label_x)),label_x)\n",
    "    plt.ylabel(\"User\")\n",
    "    plt.xlabel(algo)\n",
    "    plt.savefig(f\"User_{algo}.pdf\", bbox_inches='tight')\n",
    "    \n",
    "data = []\n",
    "label_x = list(labels.keys())[::-1]\n",
    "label_y = list([\"AGENT-SVM\", \"AGENT-USER\", \"USER-SVM\"])\n",
    "for persona in label_x:\n",
    "    data.append([])\n",
    "    for algo in label_y:\n",
    "        parts = algo.split(\"-\")\n",
    "        algo1_import = algo_import[parts[0]].loc[persona].to_numpy().reshape((1,-1))\n",
    "        algo2_import = algo_import[parts[1]].loc[persona].to_numpy().reshape((1,-1))\n",
    "        data[-1].append(cosine_similarity(algo1_import, algo2_import)[0][0])\n",
    "#             print(f\"{persona} : {a_x},{a_y} : {data[-1][-1]}\")\n",
    "plt.figure()\n",
    "plt.imshow(np.array(data).reshape((3,3,1)), cmap='RdBu',  vmin=-0.9, vmax=0.9)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(label_y)),label_y)\n",
    "plt.yticks(range(len(label_x)),label_x)\n",
    "plt.xlabel(\"Agreement\")\n",
    "plt.ylabel(\"Persona\")\n",
    "plt.savefig(f\"AgreementPersona.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4233e0d7",
   "metadata": {},
   "source": [
    "# User Questionaire Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3121ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_probs = {\n",
    "    \"USER\": n_ques_set,\n",
    "    \"SVM\": svc_maj_probs,\n",
    "    \"KNN\": knn_maj_probs,\n",
    "    \"DT\": dt_maj_probs\n",
    "}\n",
    "\n",
    "distance = []\n",
    "for algo in algo_probs.keys():\n",
    "    if algo == \"USER\":\n",
    "        continue\n",
    "    dist = []\n",
    "    for i in range(len(algo_probs[algo])):\n",
    "        user_prob = algo_probs[\"USER\"][i].reshape(1,-1)\n",
    "        clf_prob = algo_probs[algo][i].reshape(1,-1)\n",
    "        dist.append(cosine_similarity(user_prob, clf_prob)[0][0])\n",
    "    plt.hist(dist)\n",
    "    plt.title(algo)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0fc482",
   "metadata": {},
   "source": [
    "# Distribution of Labels From Different Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04386b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "svc_data[svc_data[\"IsUser\"] == True][\"Label\"].hist()\n",
    "plt.title('Support Vector Machines Classes')\n",
    "plt.figure()\n",
    "dt_data[dt_data[\"IsUser\"] == True][\"Label\"].hist()\n",
    "plt.title('Decision Tree Classes')\n",
    "plt.figure()\n",
    "knn_data[knn_data[\"IsUser\"] == True][\"Label\"].hist()\n",
    "plt.title('K-Nearest Neighbor Classes')\n",
    "plt.show()\n",
    "\n",
    "uq_data = total_data.copy()\n",
    "uq_data[\"Label\"] = \"\"\n",
    "for u in users:\n",
    "    if u in ques_data.index:\n",
    "        q_value = ques_data.loc[u]\n",
    "        uq_data.loc[u, \"Label\"] = q_value.index[q_value.argmax()]\n",
    "        \n",
    "uq_data[knn_data[\"IsUser\"] == True][\"Label\"].hist()\n",
    "plt.title('Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8a095",
   "metadata": {},
   "source": [
    "# Calculating Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_data = total_data.copy()\n",
    "dt_data[\"Label\"] = \"\"\n",
    "for i, label in enumerate(dt_maj_labels):\n",
    "    index = dt_data[dt_data[\"IsUser\"] == True].index[i*3]\n",
    "    dt_data.loc[index, \"Label\"] = list(labels.keys())[label]\n",
    "    \n",
    "knn_data = total_data.copy()\n",
    "knn_data[\"Label\"] = \"\"\n",
    "for i, label in enumerate(knn_maj_labels):\n",
    "    index = knn_data[knn_data[\"IsUser\"] == True].index[i*3]\n",
    "    knn_data.loc[index, \"Label\"] = list(labels.keys())[label]\n",
    "    \n",
    "svc_data = total_data.copy()\n",
    "svc_data[\"Label\"] = \"\"\n",
    "for i, label in enumerate(svc_maj_labels):\n",
    "    index = svc_data[svc_data[\"IsUser\"] == True].index[i*3]\n",
    "    svc_data.loc[index, \"Label\"] = list(labels.keys())[label]\n",
    "    \n",
    "uq_data = total_data.copy()\n",
    "uq_data[\"Label\"] = \"\"\n",
    "for u in users:\n",
    "    if u in ques_data.index:\n",
    "        q_value = ques_data.loc[u]\n",
    "        uq_data.loc[u, \"Label\"] = q_value.index[q_value.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f882f9",
   "metadata": {},
   "source": [
    "# Calculating Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_data = {\n",
    "    \"AGENT\": total_data,\n",
    "    \"SVM\": svc_data,\n",
    "    \"KNN\": knn_data,\n",
    "    \"DT\": dt_data,\n",
    "    \"USER\": uq_data\n",
    "}\n",
    "personas = list(labels.keys())\n",
    "\n",
    "stats = {\n",
    "    \"CollectTreasure\": [],\n",
    "    \"CollectTreasure_STD\": [],\n",
    "    \"EnemyKill\": [],\n",
    "    \"EnemyKill_STD\": [],\n",
    "    \"EndTurn\": [],\n",
    "    \"EndTurn_STD\": [],\n",
    "    \"Type\": [],\n",
    "    \"Size\": [],\n",
    "}\n",
    "indeces = []\n",
    "for p in personas:\n",
    "    for t in stats_data.keys():\n",
    "        data = stats_data[t]\n",
    "        data = data[data[\"Label\"] == p]\n",
    "        for s in stats.keys():\n",
    "            if s == \"Type\" or \"STD\" in s or \"Size\" in s:\n",
    "                continue\n",
    "            stats[s].append(data[s].mean())\n",
    "            stats[s + \"_STD\"].append(data[s].std())\n",
    "        stats[\"Type\"].append(t)\n",
    "        stats[\"Size\"].append(data.shape[0])\n",
    "        indeces.append(p)\n",
    "stats_data = pd.DataFrame(stats, index=indeces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770871bd",
   "metadata": {},
   "source": [
    "# Visualize Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e70301",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for s in stats.keys():\n",
    "    if s == \"Type\" or \"STD\" in s or \"Size\" in s:\n",
    "        continue\n",
    "    graphs.append(s)\n",
    "\n",
    "personas = list(labels.keys())\n",
    "types = [\"AGENT\", \"SVM\", \"USER\"]\n",
    "x = np.arange(len(types))\n",
    "width = 0.7/len(types)\n",
    "\n",
    "for s in graphs:\n",
    "    plt.figure()\n",
    "    for i,t in enumerate(types):\n",
    "        means = []\n",
    "        stds = []\n",
    "        for p in personas:\n",
    "            data = stats_data.loc[p]\n",
    "            data = data[data[\"Type\"] == t]\n",
    "            means.append(data[s].to_numpy()[0])\n",
    "            stds.append(data[s + \"_STD\"].to_numpy()[0] / np.sqrt(data[\"Size\"].to_numpy()[0]))\n",
    "        plt.bar(x + (i-int(len(types)/2))*width, means, width, yerr=stds, label=t)\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(x, labels=personas)\n",
    "    plt.legend()\n",
    "    plt.title(s)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891c3f6",
   "metadata": {},
   "source": [
    "# Calculate User Persona Change Between Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c0218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_diff_labels = dt.predict(n_maj_test_set)\n",
    "knn_diff_labels = knn.predict(n_maj_test_set)\n",
    "svc_diff_labels = svc.predict(n_maj_test_set)\n",
    "\n",
    "dt_maj_labels = get_majority_voting(dt, n_maj_test_set)\n",
    "knn_maj_labels = get_majority_voting(knn, n_maj_test_set)\n",
    "svc_maj_labels = get_majority_voting(svc, n_maj_test_set)\n",
    "\n",
    "predict_labels = {\n",
    "    \"DT\": [dt_diff_labels, dt_maj_labels],\n",
    "    \"KNN\": [knn_diff_labels, knn_maj_labels],\n",
    "    \"SVM\": [svc_diff_labels, svc_maj_labels]\n",
    "}\n",
    "\n",
    "for algo in predict_labels.keys():\n",
    "    value = [0, 0, 0]\n",
    "    algo_data = predict_labels[algo]\n",
    "    for i, label in enumerate(algo_data[0]):\n",
    "        if label != algo_data[1][int(i/3)]:\n",
    "            value[i % 3] += 1\n",
    "    plt.figure()\n",
    "    plt.bar(range(len(value)), value)\n",
    "    plt.title(algo)\n",
    "    plt.xlabel(\"Order\")\n",
    "    plt.ylabel(\"Classification Mistakes\")\n",
    "    plt.xticks(range(len(value)), labels=range(len(value)))\n",
    "    plt.show()\n",
    "\n",
    "print()\n",
    "\n",
    "for algo in predict_labels.keys():\n",
    "    algo_data = predict_labels[algo]\n",
    "    dt_data = total_data.copy()\n",
    "    level_value = {}\n",
    "    for i, label in enumerate(algo_data[0]):\n",
    "        index = dt_data[dt_data[\"IsUser\"] == True].index[i]\n",
    "        map_number = dt_data.loc[index, \"MapNumber\"][0]\n",
    "        if map_number not in level_value:\n",
    "            level_value[map_number] = 0\n",
    "        if label != algo_data[1][int(i/3)]:\n",
    "            level_value[map_number] += 1\n",
    "    values = []\n",
    "    x_values = []\n",
    "    for l in level_value.keys():\n",
    "        size = len(dt_data[(dt_data[\"MapNumber\"] == l) & (dt_data[\"IsUser\"] == True)])\n",
    "        level_value[l] /= size\n",
    "        values.append(level_value[l])\n",
    "        x_values.append(l)\n",
    "    plt.figure()\n",
    "    plt.bar(range(len(values)), values)\n",
    "    plt.title(algo)\n",
    "    plt.xlabel(\"Maps\")\n",
    "    plt.ylabel(\"Classification Mistakes\")\n",
    "    plt.xticks(range(len(x_values)), labels=x_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d47081",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_data = {\n",
    "    \"AGENT\": total_data,\n",
    "    \"SVM\": svc_data,\n",
    "    \"USER\": uq_data\n",
    "}\n",
    "\n",
    "for agent in stats_data:\n",
    "    for persona in labels:\n",
    "        value = stats_data[agent].query(f\"Label == '{persona}'\")[\"ReachStairs\"].sum()\n",
    "        total = len(stats_data[agent].query(f\"Label == '{persona}'\"))\n",
    "        print(f\"{agent} - {persona}: {value / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ed762",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_data = {\n",
    "    \"DT\": dt_data,\n",
    "    \"KNN\": knn_data,\n",
    "    \"SVM\": svc_data,\n",
    "    \"USER\": uq_data\n",
    "}\n",
    "\n",
    "for key in stats_data:\n",
    "    if key == \"USER\":\n",
    "        continue\n",
    "    agreement = 0\n",
    "    total = 0\n",
    "    for user in users:\n",
    "        if user in svc_data.index:\n",
    "            key_label = stats_data[key].loc[user][\"Label\"]\n",
    "            user_label = stats_data[\"USER\"].loc[user][\"Label\"]\n",
    "            if key_label[0] == user_label[0]:\n",
    "                agreement += 1\n",
    "            total += 1\n",
    "    print(f\"{key} agreemenet: {agreement / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_maj_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ques_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ffb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8171e9d24db1aee8ec92a108d69ccf55c456965c4b60d3f0b4ce0790439bd2b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
